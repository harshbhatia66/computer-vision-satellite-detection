{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, Reshape, multiply, Add, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model, layers\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "66/66 [==============================] - 912s 14s/step - loss: 9.5265 - accuracy: 0.5445 - val_loss: 0.9064 - val_accuracy: 0.6362\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 386s 6s/step - loss: 0.9816 - accuracy: 0.6460 - val_loss: 0.8596 - val_accuracy: 0.6667\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 393s 6s/step - loss: 0.9601 - accuracy: 0.6617 - val_loss: 0.9004 - val_accuracy: 0.6705\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 398s 6s/step - loss: 0.9302 - accuracy: 0.6656 - val_loss: 0.7767 - val_accuracy: 0.7029\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 391s 6s/step - loss: 0.8465 - accuracy: 0.6980 - val_loss: 0.7785 - val_accuracy: 0.7048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x38d75a640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to load and preprocess the dataset\n",
    "def load_preprocessed_dataset(fname):\n",
    "    # Load the dataset\n",
    "    data = np.genfromtxt(fname, dtype=['|S19', '<f8', '|S4'], names=[\n",
    "                         'path', 'probability', 'type'])\n",
    "    image_fnames = np.char.decode(data['path'])\n",
    "    probs = data['probability']\n",
    "    types = np.char.decode(data['type'])\n",
    "\n",
    "    # Define a function to preprocess the images\n",
    "    def load_and_preprocess_image(fname):\n",
    "        with Image.open(fname) as image:\n",
    "            # Preprocess image for VGG-16\n",
    "            image = image.convert('RGB')\n",
    "            image = image.resize((224, 224))\n",
    "            image = np.array(image)\n",
    "            image = vgg16.preprocess_input(image)\n",
    "            return image\n",
    "    \n",
    "    # Load and preprocess images\n",
    "    dir = os.path.dirname(fname)\n",
    "    images = np.array([load_and_preprocess_image(os.path.join(dir, fn))\n",
    "                       for fn in image_fnames])\n",
    "    \n",
    "    # Convert probabilities to categorical labels\n",
    "    labels = to_categorical(probs * 3, num_classes=4)\n",
    "    \n",
    "    return images, labels, types\n",
    "\n",
    "# Load the dataset\n",
    "images, labels, types = load_preprocessed_dataset('elpv-dataset/labels.csv')\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define SE Block for attention\n",
    "def se_block(input_feature, ratio=8):\n",
    "    \"\"\" Create a squeeze and excitation block \"\"\"\n",
    "    channel_axis = -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "\n",
    "    se_feature = GlobalAveragePooling2D()(input_feature)\n",
    "    se_feature = Reshape((1, 1, channel))(se_feature)\n",
    "    se_feature = Dense(channel // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se_feature)\n",
    "    se_feature = Dense(channel, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se_feature)\n",
    "\n",
    "    se_feature = multiply([input_feature, se_feature])\n",
    "    return se_feature\n",
    "\n",
    "# Load the VGG-16 model without the top layer (include_top=False)\n",
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Adding SE blocks to VGG\n",
    "layer_outputs = [layer.output for layer in base_model.layers]\n",
    "attention_layer_1 = se_block(layer_outputs[-2]) # Add attention to a layer near the end\n",
    "attention_layer_2 = se_block(layer_outputs[-5]) # Add attention to another layer\n",
    "\n",
    "# Combine these layers with the rest of the model\n",
    "x = layers.Concatenate()([attention_layer_1, attention_layer_2])\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile and train the model as before\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
